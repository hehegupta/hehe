import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import (accuracy_score, confusion_matrix, recall_score,
fl_score, roc_auc_score, precision_score)
from sklearn. naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder, label_binarize
# Load Iris dataset
df = pd.read_csv(r"C: \Users\ISHAAN\Desktop\New folder (2) \iris.data", header=None)
df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species' ]

# Encode target
le = LabelEncoder ()
df ['species_encoded' ] = le.fit_transform(df ['species' ])
X = df[['sepal_length' , 'sepal_width', 'petal_length', 'petal_width' ]]
y = df ['species_encoded' ]

# Binary classification for metrics (Iris-setosa vs not)
df['binary_label'] = (df ['species' ] == 'Iris-setosa') .astype (int)
y_binary = df ['binary_label' ]

# Split for binary metrics
X train, X_test, y_train_bin, y_test_bin = train_test_split (X, y_binary, test_size=0.2, random_state=42)

# Train model
model = GaussianNB ()
model.fit (X_train, y_train_bin)
y_pred_bin = model.predict (X_test)

# Confusion Matrix
cm = confusion_matrix (y_test_bin, y_pred_bin)
TN, FP, FN, TP = cm. ravel ()

# Metrics
acc = accuracy_score (y_test_bin, y_pred_bin)
error = 1 - acc
recall = recall_score(y_test_bin, y_pred_bin)
precision = precision_score(y_test_bin, y_pred_bin)
Il = Il_score (y_test_pin, y_prea_pin)
specificity = TN / (TN + FP)

# AUC
y_proba = model.predict_proba (X_test) [ :, 1]
auc = roc_auc_score (y_test_bin, y_proba)

# Print metrics
print (" === Naive Bayes Classification Metrics === ")
print (f"Accuracy: {acc: . 4f} ")
print (f"Error Rate: {error: . 4f} ")
print (f"Recall (Sensitivity) : {recall: .4f} ")
print (f"Specificity: {specificity: . 4f} ")
print (f"Fl Score: {f1 :. 4f}")
print (f"Precision: {precision :. 4f} ")
print (f"AUC: {auc: . 4f}")
print (f"Confusion Matrix: \n{cm)")
print (f"TP: {TP), TN: {TN}, FP: {FP}, FN: {FN}")

# Cross-validation on full binary labels
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score (model, X, y_binary, cv=kfold, scoring='accuracy' )
print ("\n === Cross-Validation === ")
print ("CV Accuracy Scores:", cv_scores)
print ("Mean CV Accuracy:", np.mean (cv_scores) )